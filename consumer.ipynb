{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Spark streaming and Kafka\n",
    "import os  \n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2 pyspark-shell'  \n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext  \n",
    "from pyspark.streaming.kafka import KafkaUtils  \n",
    "from datetime import datetime\n",
    "\n",
    "# Define micro batch window and sliding window\n",
    "batch_interval = 1\n",
    "window_length = 12 * batch_interval\n",
    "frequency = 6 * batch_interval\n",
    "\n",
    "# Define spark context\n",
    "sc = SparkContext(appName=\"CTR\")\n",
    "sc.setLogLevel(\"WARN\")\n",
    "ssc = StreamingContext(sc, batch_interval)\n",
    "\n",
    "# Create RDD\n",
    "directKafkaStream = KafkaUtils.createDirectStream(ssc, ['topic_click'], {\"metadata.broker.list\": 'localhost:9092'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = directKafkaStream.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define function for MapReduce\n",
    "import re\n",
    "def mk_int(s):\n",
    "    s = s.strip()\n",
    "    return int(s) if s else 0\n",
    "def tuple_sum(a, b):\n",
    "    return [a[0]+b[0], a[1]+b[1]]\n",
    "def tuple_minus(a, b):\n",
    "    return [a[0]-b[0], a[1]-b[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert stream to MySQL database\n",
    "def insert_into_mysql(group_id, clicks, total):\n",
    "    import MySQLdb\n",
    "    conn = MySQLdb.connect(host = \"localhost\", user = \"uid\", passwd = \"pwd\", db = \"db\")\n",
    "    \n",
    "    # Control Start and End of ABtest\n",
    "    try:\n",
    "        x = conn.cursor()\n",
    "        x.execute(\"select yn from abonoff;\")\n",
    "        abonoff = 0\n",
    "        for row in x:\n",
    "            abonoff = int(row[0])\n",
    "        if abonoff == 1:\n",
    "            if group_id == 1:\n",
    "                x.execute(\"\"\"INSERT INTO ctr_4 VALUES (%s,%s,%s,%s,%s,%s,%s)\"\"\",(datetime.now(), \"test\", clicks, total, \" \", \" \", datetime.now()))\n",
    "            else:\n",
    "                x.execute(\"\"\"INSERT INTO ctr_4 VALUES (%s,%s,%s,%s,%s,%s,%s)\"\"\",(datetime.now(), \"control\", clicks, total, \" \", \" \", datetime.now()))\n",
    "        else:\n",
    "            x.execute(\"\"\"INSERT INTO ctr_4 VALUES (%s,%s,%s,%s,%s,%s,%s)\"\"\",(datetime.now(), \"control\", clicks, total, \" \", \" \", datetime.now()))\n",
    "        conn.commit()\n",
    "        return (str(group_id) + \" \" + str(abonoff), 100.0 * clicks / total)\n",
    "    except Exception, e:\n",
    "        conn.rollback()\n",
    "        return (str(e), 100.0 * clicks / total)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_info = sc.textFile(\"s3n://s3bucketnm/UserInfo.tsv\")\n",
    "user_info = user_info.map(lambda line: line.split(\"\\t\")[:])\n",
    "type(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spark streaming reduce by key and window\n",
    "ctr = lines.map(lambda line: line.split(\"\\t\")) \\\n",
    "    .map(lambda click: (click[0], mk_int(click[-1]))) \\\n",
    "    .reduceByKey(lambda a, b: a+b) \\\n",
    "    .map(lambda kvpair: (mk_int(kvpair[0])%2, (kvpair[1], 1))) \\\n",
    "    .reduceByKeyAndWindow(lambda a, b: tuple_sum(a, b), None, window_length, frequency) \\\n",
    "    .flatMap(lambda row: insert_into_mysql(row[0], row[1][0], row[1][1]) )\n",
    "    \n",
    "ctr.pprint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssc.start()  \n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc.stop()\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
